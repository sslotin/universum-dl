{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генеративные состязательные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой тетрадке мы научимся писать сети на чуть более низком уровне."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем две сети: одна генерирует данные, другая отличает фейковые от настоящих. Рано или поздно у нас будет генератор данных, который можно будет использовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассказывать ли WGAN и идеи Арьевского или всё ещё обычный? По-моему уже пора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ганы стали применять очень много где.\n",
    "\n",
    "Если после 2012 года и работы ЛеКуна было много хайпа, то после 2014 его стало совсем много, как раз из-за ганов.\n",
    "\n",
    "Вот наиболее значимые из них:\n",
    "\n",
    "- **CycleGAN**.\n",
    "- **WGAN**.\n",
    "- **Unsupervised NMT**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "import numpy as np\n",
    "from mnist import X\n",
    "X = X.reshape(-1, 28, 28)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "batch_size = 64\n",
    "sample_interval = 50\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генератор сделаю полносвязным. Для желающих: напишите через deconvolution-ы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = Sequential([\n",
    "    Dense(256, input_dim=latent_dim),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dense(512),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dense(784),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Reshape((28, 28))\n",
    "])\n",
    "\n",
    "#G.compile()\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = Sequential([\n",
    "    Dense(512, input_dim=784),\n",
    "    LeakyReLU(),\n",
    "    Dense(256),\n",
    "    LeakyReLU(),\n",
    "    Dense(64),\n",
    "    LeakyReLU(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "D.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сольем их в одну модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = Input(shape=(latent_dim,))\n",
    "img = G(z)\n",
    "validity = D(img)\n",
    "GAN = Model(z, validity)\n",
    "GAN.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое содержательное: цикл обучения. Его нужно написать вручную — model.fit() не прокатит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# эпохи — это в смысле батчи\n",
    "for epoch in range(epochs):\n",
    "    real = X[np.random.randint(0, X.shape[0], batch_size)] # так можно посэмплить батч\n",
    "    noise = np.random.randn((batch_size, latent_dim))\n",
    "    fake = G.predict(noise)\n",
    "    \n",
    "    d_loss_real = D.train_on_batch(real, np.ones((batch_size, 1)))\n",
    "    d_loss_fake = D.train_on_batch(fake, np.zeros((batch_size, 1)))\n",
    "    d_loss = np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "    g_loss = GAN.train_on_batch(noise, valid)\n",
    "\n",
    "    print (\"%d, D loss: %f, G loss: %f\" % (epoch, d_loss[0], g_loss))\n",
    "\n",
    "    if epoch % sample_interval == 0:\n",
    "        # выводим то, что в батче\n",
    "        # дополнительных вычислений это не стоит\n",
    "        fake = fake.reshape(-1, 28, 28)\n",
    "        \n",
    "        fig, axs = plt.subplots(8, 8)\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                axs[i,j].imshow(gen_imgs[i*8 + j, :,:, 0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вассерштейново расстояние и эвристики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение GAN-ов не на игрушечных данных **очень** нестабильно. Придумали множество костылей, чтомы его улучшить:\n",
    "* Делать лэйблы не 0 и 1, а 0.1 и 0.9 или что-то близкое.\n",
    "* Выкинуть нафиг эту KL-дивергенцию. Оказывается, она не сходится и может вызывать взрывающие / затухающие градиенты. Вместо неё можно использовать Earth Moving.\n",
    "* Напрямую делать penalty на слишком большой или слишком маленький градиент.\n",
    "* На каждую итерацию итератора несколько итераций дискриминатора."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
