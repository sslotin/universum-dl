{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генеративные состязательные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py\n",
    "\n",
    "https://habr.com/post/332000/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gan](images/gan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN-ы состоят из двух частей:\n",
    "\n",
    "1. Генератор (будем обозначать его $G$), который сэмплит случайные числа из какого-то определенного распределения (например, нормального) и генерируют из них объекты, которые идут на вход второй сети.\n",
    "\n",
    "2. Дискриминатор $D$, который получает на вход объекты из выборки и созданные генератором, и учится предсказывать вероятность того, что конкретный объект реальный (он выдает скаляр — число от 0 до 1).\n",
    "\n",
    "GAN-ы нужны для «обучения» распределения очень сложных данных (например, изображений), и применяются очень много где, но не в продакшене, а скорее в ресёрче, потому что их на данный момент очень трудно обучать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогия: представьте двух людей — один пытается подделать произведения искусства, а второй пытается это распознать. Рано или поздно у нас в результате такой длящейся бесконечно долго игры получаются два очень полезных ресурса — генератор **новых** произведений искусства и распознаватель подделок — оба из которых можно применить где-нибудь ещё (а можно и просто наслаждаться синтетическим искусством)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN — это такое прямое прохождение теста Тьюринга. Примерно это и мотивирует все их применения в генеративных моделях. Например, колоризацию «правильно» делать так: обучаем одну сеть, которая раскрашивает, а вторая — определяет качество раскраски. Генерация диалогов или перевода — точно так же, вместо языковой модели — две играющие друг против друга сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все бы прекрасно, но у нас есть проблема — мы не знаем, как мерить качество GAN-ов и вообще всех генеративных моделей. Эта проблема ещё не решена. Ничего умнее мнения независимых сетей-классификаторов («inception score») или субъективных человеческих оценок не придумали. Пока что у нас вообще никаких способов оценить качество модели, кроме того, как посмотреть на данные раз в сколько-то эпох. Это всё заметно тормозит архитектурный поиск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unsupervised NMT\n",
    "* CycleGAN\n",
    "* Conditional GAN\n",
    "* InfoGAN\n",
    "* Морфинг\n",
    "* VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой тетрадке мы будем научимся писать сети на чуть более низком уровне, потому что стандартный .fit() для наших целей недостаточно гибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "import numpy as np\n",
    "from mnist import X\n",
    "X = X.reshape(-1, 28, 28)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "batch_size = 64\n",
    "sample_interval = 50\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генератор сделаем полносвязным. Желающие могут написать через deconvolution-ы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = Sequential([\n",
    "    Dense(256, input_dim=latent_dim),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dense(512),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Dense(784),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    Reshape((28, 28))\n",
    "])\n",
    "\n",
    "#G.compile()\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = Sequential([\n",
    "    Dense(512, input_dim=784),\n",
    "    LeakyReLU(),\n",
    "    Dense(256),\n",
    "    LeakyReLU(),\n",
    "    Dense(64),\n",
    "    LeakyReLU(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "D.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сольем их в одну модель, как делали с автоэнкодерами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = Input(shape=(latent_dim,))\n",
    "img = G(z)\n",
    "D.trainable = False # тут нам нужно отключить ему градиенты, чтобы при обучении всего GAN-а они не менялись\n",
    "validity = D(img)\n",
    "GAN = Model(z, validity)\n",
    "GAN.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое содержательное это цикл обучения. Его нужно написать вручную — model.fit() не прокатит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# эпохи — это в смысле батчи\n",
    "for epoch in range(epochs):\n",
    "    # сначала обучим дискриминатор\n",
    "    real = X[np.random.randint(0, X.shape[0], batch_size)] # так можно посэмплить батч вручную\n",
    "    noise = np.random.randn((batch_size, latent_dim))\n",
    "    fake = G.predict(noise)\n",
    "    \n",
    "    d_loss_real = D.train_on_batch(real, np.ones((batch_size, 1)))\n",
    "    d_loss_fake = D.train_on_batch(fake, np.zeros((batch_size, 1)))\n",
    "    d_loss = np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # теперь обучаем генератор\n",
    "    noise = np.random.randn((batch_size, latent_dim))\n",
    "    g_loss = GAN.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "    print (\"%d, D loss: %f, G loss: %f\" % (epoch, d_loss[0], g_loss))\n",
    "\n",
    "    if epoch % sample_interval == 0:\n",
    "        # выводим то, что в батче\n",
    "        # дополнительных вычислений это не стоит\n",
    "        fake = fake.reshape(-1, 28, 28)\n",
    "        \n",
    "        fig, axs = plt.subplots(8, 8)\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                axs[i,j].imshow(gen_imgs[i*8 + j])\n",
    "                axs[i,j].axis('off')\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close() # не уверен, что это нужно; я это откуда-то скопировал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вассерштейново расстояние и эвристики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение GAN-ов не на игрушечных данных **очень** нестабильно. Придумали множество костылей, чтомы его улучшить:\n",
    "* Делать лэйблы не 0 и 1, а 0.1 и 0.9 или что-то близкое.\n",
    "* Выкинуть нафиг эту KL-дивергенцию. Оказывается, она не сходится и может вызывать взрывающие / затухающие градиенты. Вместо неё можно использовать Earth Moving.\n",
    "* Напрямую делать penalty на слишком большой или слишком маленький градиент.\n",
    "* На каждую итерацию итератора несколько итераций дискриминатора."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
